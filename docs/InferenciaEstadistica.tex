% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Inferencia},
  pdfauthor={Rodrigo Zepeda-Tello y Luis Carlos Bernal},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{xcolor}
\definecolor{ejemplocolor}{HTML}{0A7000}
\definecolor{recuadrocolor}{HTML}{3DB295}
\definecolor{teoremacolor}{HTML}{900C3F}
\definecolor{propiedadescolor}{HTML}{C301AC}
\definecolor{importantecolor}{HTML}{FF0000}
\definecolor{corolariocolor}{HTML}{0CABAD}
\definecolor{lemacolor}{HTML}{0BA50B}
\definecolor{ejerciciocolor}{HTML}{183283}
\definecolor{definicioncolor}{HTML}{183283}
\definecolor{formulacolor}{HTML}{137AA4}


\newenvironment{Ejemplo}
{\begin{mdframed}[
  linecolor=ejemplocolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Definicion}
{\begin{mdframed}[
  linecolor=definicioncolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Recuadro}
{\begin{mdframed}[
  linecolor=recuadrocolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Teorema}
{\begin{mdframed}[
  linecolor=teoremacolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Propiedades}
{\begin{mdframed}[
  linecolor=propiedadescolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Importante}
{\begin{mdframed}[
  linecolor=importantecolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Corolario}
{\begin{mdframed}[
  linecolor=corolariocolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Lema}
{\begin{mdframed}[
  linecolor=lemacolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Ejercicio}
{\begin{mdframed}[
  linecolor=ejerciciocolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}

\newenvironment{Formula}
{\begin{mdframed}[
  linecolor=formulacolor,
  skipabove=12pt,
  skipbelow=12pt,
  roundcorner=20pt,
  splittopskip=2\topsep]}
{\end{mdframed}}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Inferencia}
\author{Rodrigo Zepeda-Tello y Luis Carlos Bernal}
\date{2021-01-12}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{intro}{%
\chapter{Introducción}\label{intro}}

\hypertarget{estaduxedstica-y-muestras}{%
\section{Estadística y muestras}\label{estaduxedstica-y-muestras}}

La \href{https://plato.stanford.edu/entries/statistics/\#StaInd}{enciclopedia Stanford de filosofía} establece la siguiente definición de estadística\footnote{Traducción y subrayado de Rodrigo}.

\begin{Definicion}
\textbf{Estadística} La estadística es una disciplina matemática y
conceptual que se enfoca en la relación entre datos e hipótesis. Los
datos son registros de observaciones o eventos en un estudio científico,
por ejemplo, un conjunto de mediciones de individuos de una población.
Los datos que son obtenidos se conoce como la muestra, datos muestrales,
o simplemente los datos, y todas las posibles muestras posibles en un
estudio forman una colección llamada el espacio muestra. Las hipótesis,
por su parte, son enunciados generales sobre el sistema objetivo de la
investigación científica, por ejemplo, expresar un hecho general sobre
todos los individuos en la población. Una hipótesis estadística es un
enunciado general que puede ser expresada como una distribución de
probabilidad sobre el espacio muestral, es decir, ésta determina una
probabilidad para cada una de las posibles muestras.
\end{Definicion}

De manera breve, la estadística es una disciplina que se encarga de, a través de muestras (cuantificadas como datos), describir el mundo. Y hay muchas cosas por describir: asociaciones, causalidad, realizar predicciones, establecer mecanismos de funcionamiento de objetos, etc. Es así como se establece su objetivo el cual de acuerdo con \citet{wackerly} es:

\begin{quote}
realizar una inferencia sobre la población con base en la información contenida en una muestra de dicha población y proveer una medida asociada de qué tan buena es la inferencia.
\end{quote}

Dentro de la definición previa y objetivos hay que destacar varios términos que son de importancia. La primera es la \textbf{población}, cualquier conjunto (no vacío) de objetos. Una \textbf{población} es lo más general posible, no necesariamente involucra personas o seres vivos. Algunos ejemplos de poblaciones incluyen: las personas que viven en Guatemala (si me interesa saber algo de los guatemaltecos en general), los árboles del Amazonas (si quiero saber cosas de ecología), los perros callejeros en Ciudad de México, los consumidores de una marca de cereal, los coches que transitan por Dubai, los granos de arena en una playa específica de Cancún, las células T dentro de los seres humanos o los metales pesados.

Más relevante que la población (para nuestros propósitos) es la \textbf{población objetivo} El conjunto de elementos que formarán parte del estudio. Definir la \textbf{población objetivo} es complicado en algunas situaciones; por ejemplo, si se desea saber si \emph{los mexicanos} están a favor o en contra de legalizar la marihuana hay que establecer quiénes son \emph{los mexicanos}. ¿Cuentan las personas con nacionalidad mexicana que residen en el extranjero? ¿Cuentan los menores de edad? ¿Qué pasa con los extranjeros que son residentes? De nuevo, la población objetivo no necesariamente son personas, es sólo aquello que nos interesa medir.

Idealmente el estudio estadístico sería sobre la población objetivo. Por ejemplo, si nos interesa estudiar la evolución de los enfermos de VIH, la \textbf{población objetivo} serían los enfermos. Sin embargo, en el mundo real es imposible conseguir a toda la población objetivo (dentro de los enfermos, por ejemplo, están aquellos que aún no saben que tienen la enfermedad y no acudirían a nuestro estudio). La \textbf{población muestreada} resulta de esta dificultad. La \textbf{población muestreada} es el conjunto de elementos sobre los cuales se construyó la muestra para el análisis estadístico. En el caso de los enfermos de VIH la \textbf{población muestreada} podrían ser las personas que para una fecha específica habían sido diagnosticadas (y nos olvidamos de quienes desconocen su diagnóstico) o toda la población mexicana (y llevamos kits de diagnóstico con nosotros cuando diagnostiquemos). En encuestas de consumo, por ejemplo, usualmente no se muestrean zonas remotas o de muy bajos recursos por lo que la \textbf{población muestreada} no coincide con la \textbf{población objetivo} (todos los consumidores) sino que son sólo los consumidores de mayor poder adquisitivo. En encuestas de elecciones si bien la población objetivo son \emph{todas las personas que voten el día de la elección}, como la mayoría se hacen \emph{antes} de la elección (exceptuando las de salida) entonces se aproxima la definición de \emph{votante} buscando incluir sólo aquellos que estén registrados en el padrón electoral o bien aquellos que al ser encuestados digan que \emph{sí} van a votar. Aquí la \textbf{población muestreada} tampoco coincide con la objetivo.

Una \textbf{muestra} es un subconjunto de la población muestreada. Si la muestra coincide con la población muestreada (es decir, muestreaste a todo el mundo) se dice que es un \textbf{censo}. Si se tiene un censo se conoce TODA la población por lo que no es necesario hacer ningún análisis de inferencia (ya sabes todo de todos). Puedes realizar predicciones o descripciones. Ejemplos de censos son las encuestas de fin de cursos, las calificaciones de todo un grupo o el registro de todas las compras de todas las personas en una tienda en línea.

\begin{quote}
\textbf{Ojo} No hay que confundir la definición de \textbf{muestra} con la definición estadística de \textbf{muestra aleatoria} (ver más adelante) la cual es un tipo muy específico de muestra obtenida bajo reglas restrictivas.
\end{quote}

Finalmente hay que definir \textbf{inferencia}, el propósito de estas notas. Para ello usaremos el ejemplo y una versión adaptada de la definición de \citet{boghossian2014inference}. Considera que sabes dos verdades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Llovió anoche
\item
  Cuando llueve el suelo se moja
\end{enumerate}

por lo que esta mañana \emph{infieres} que el suelo estará mojado y sales de tu casa con botas y no con chanclas. El proceso de \emph{inferir} parece una consecuencia lógica de las premisas 1 y 2 pero no lo es exactamente: hoy es otro día y si hizo suficiente calor en la noche el agua pudo haberse evaporado del suelo. De ahí que definamos inferencia como:

\begin{quote}
Realizar un juicio el cual se explica a partir de premisas que suponemos verdaderas.
\end{quote}

En particular \textbf{la inferencia estadística} será la rama de la estadística cuyo propósito es

\begin{quote}
Realizar juicios probabilísticos a partir de datos que suponemos verdaderos.
\end{quote}

Aquí es necesario desglosar un poco la definición:

\begin{itemize}
\item
  Se habla de \textbf{juicios probabilísticos} pues nuestros juicios nunca van a ser tan certeros como \texttt{el\ suelo\ està\ mojado}. Más bien van a ser del estilo \texttt{hay\ una\ probabilidad\ muy\ alta\ de\ que\ el\ suelo\ esté\ mojado} o \texttt{nueve\ de\ cada\ diez\ veces\ el\ suelo\ estará\ mojado}.
\item
  La \textbf{suposición de verdad} de los datos es muy relevante. Imagina el siguiente experimento: tu amiga borracha durante una fiesta se le ocurre que, de la nada, desarrolló poderes de psíquica y puede adivinar el futuro resultado de una moneda (cara o cruz). Tiras una moneda diez veces y todas las veces tu amiga hace una predicción correcta. \emph{Considerando los datos como verdad concluirías que tu amiga es psíquica}. Una observación a profundidad de la moneda quizá te revele que es una moneda truqueada que siempre cae en cara. En ese momento cambiarías la \textbf{suposición de verdad} de los datos y la inferencia de que tu amiga es psíquica.
\end{itemize}

A lo largo de este libro aprenderemos lo básico para realizar inferencias estadísticas: observar datos y suponer verdades a partir de ellos. Tristemente la estadística nunca nos va a poder dar la verdad absoluta pero, si lo hacemos bien, es quizá lo más cerca que podamos estar de ella.

\hypertarget{modelos}{%
\section{Modelos}\label{modelos}}

La estadística funciona a partir de la construcción de \textbf{modelos}. Estos pretenden ser una forma de describir el mundo mediante teoría de la probabilidad y lo que se busca es utilizar dicha teoría para realizar inferencias. Estos modelos teóricos representan la forma en la que suponemos funciona la población. Para propósitos de estas notas diremos que los modelos viven \emph{en el mundo de los modelos} o \emph{mundo de las ideas}. Los datos observados, para poder distinguirlos, viven en \emph{el mundo real}. Muchos de los modelos (no todos) se componen de \textbf{parámetros} que requieren para poder funcionar los cuales son estimados mediante \textbf{estadísticos} que se construyen a partir de los datos.

Para nuestros propósitos, los modelos que usaremos siempre construirán una población de la siguiente forma:

\begin{Definicion}
\hypertarget{poblaciuxf3n}{%
\subsubsection{Población}\label{poblaciuxf3n}}

Una población es un conjunto no vacío de variables (o vectores)
aleatorias. \[
\mathcal{X} = \{ X_1, X_2, \dots \}
\]
\end{Definicion}

Una población no necesariamente es finita. Por ejemplo, si nos interesa saber el tiempo que tarda un cliente en ser atendido en una llamada telefónica al banco quizá podemos suponer que la llamada telefónica tiene una duración descrita por un modelo \(\text{Exponencial}(\lambda)\). La población sería el conjunto infinito de todas las posibles llamadas telefónicas que se pueden realizar bajo este modelo. Por otro lado, un ejemplo finito de una población, son las caras de una moneda en un experimento donde busquemos, para una moneda específica, si caen más caras que cruces (cae más de un lado que del otro).

Una \textbf{muestra} es cualquier subconjunto (posiblemente infinito también) de la población.

\begin{Definicion}
\hypertarget{muestra}{%
\subsubsection{Muestra}\label{muestra}}

Una muestra \(\mathcal{M}\) de una población \(\mathcal{X}\) es
cualquier subconjunto no vacío de \(\mathcal{X}\). Es decir,
\(\mathcal{M}\) es una muestra de \(\mathcal{X}\) si: \[
 \mathcal{M} \subseteq \mathcal{X}
\]
\end{Definicion}

Pocas veces hablaremos de \emph{muestras} de manera general y nos enfocaremos, sobre todo, en \textbf{muestras aleatorias}:

\begin{Definicion}
\hypertarget{muestra-aleatoria}{%
\subsubsection{Muestra aleatoria}\label{muestra-aleatoria}}

Una muestra aleatoria de tamaño \(n\), \(\mathcal{X}_{(n)}\), de una
población \(\mathcal{X}\) es un subconjunto finito (de tamaño \(n\)), no
vacío de \(\mathcal{X}\) donde sus elementos son \textbf{variables
aleatorias independientes idénticamente distribuidas}. Es decir,
\(\mathcal{X}_{(n)}\) es una muestra de \(\mathcal{X}\) si:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Es una muestra}: \(\mathcal{X}_{(n)} \subseteq \mathcal{X}\),
\item
  \textbf{de tamaño \(n\)}:
  \(\textrm{Cardinalidad}\Big( \mathcal{X}_{(n)} \Big) = n\),
\item
  \textbf{con variables independientes}: si
  \(X_i, X_j \in \mathcal{X}_{(n)}\) entonces
  \(\mathbb{P}(X_i \in A , X_j \in B) = \mathbb{P}(X_i \in A)\cdot\mathbb{P}(X_j \in B)\)
  para \(A,B\) conjuntos \emph{medibles},
\item
  \textbf{idénticamente distribuidas}: para todo \(i = 1,2,\dots, n\) se
  tiene que \(X_i\) tiene función de distribución acumulada \(F_X\).
\end{enumerate}
\end{Definicion}

El punto 4. de la definición pide que todas las variables descritas tengan la misma distribución. Por ejemplo, podemos pedir que todas sean exponenciales con el mismo parámetro o todas sean gamma con los mismos parámetros. El punto es que todas las variables aleatorias estén descritas con el mismo modelo y sean independientes entre sí.

El punto 3. de la definición puede escribirse de otras formas más amigables, por ejemplo, si suponemos que las variables aleatorias son continuas y tienen densidad \(f_X\) entonces la independencia puede escribirse como:
\[
f_X(x_i, x_j) = f_X(x_i) \cdot f_X(x_j)
\]
mientras que si son discretas con función de masa de probabilidad \(p_X\) tenemos:
\[
p_X(x_i, x_j) = p_X(x_i) \cdot p_X(x_j)
\]

La \textbf{muestra observada} así como \textbf{la muestra aleatoria observada} es el conjunto de \emph{datos} que realmente viste. Mientras que la \textbf{muestra} y la \textbf{muestra aleatoria} viven \emph{en el mundo de los modelos} y son variables aleatorias (constructos teóricos, como sabes, bastante complejos), la \textbf{muestra observada} es lo que se midió. Antes de dar la definición veamos un ejemplo con un dado.

\begin{Ejemplo}
\hypertarget{tiro-de-un-dado}{%
\subsubsection{Tiro de un dado}\label{tiro-de-un-dado}}

Se realiza un experimento para saber si un dado es justo (todos los
lados tienen la misma probabilidad). Para ello se tira el dado
\(n = 10\) veces y se registran los tiros: \(2,6,1,3,3,3,5,1,3,2\).

\emph{Mundo del modelo}

La población en este caso es el conjunto infinito de todos los posibles
tiros del dado. De ese conjunto obtenemos una muestra aleatoria de
tamaño \(n = 10\) (suponemos que los tiros son independientes entre sí)
dada por: \[
X_{(n)} = \{ X_1, X_2, X_3, \dots, X_{10}\}
\] donde \(X_i\) tiene la siguiente distribución: \[
\mathbb{P}(X_i = z) = 
\begin{cases}
p_1  \text{ si } z = 1 \\
p_2  \text{ si } z = 2 \\
p_3  \text{ si } z = 3 \\
p_4  \text{ si } z = 4 \\
p_5  \text{ si } z = 5 \\
p_6  \text{ si } z = 6 \\
0  \text{ en otro caso.}
\end{cases}
\] donde \(\sum_{k = 1}^n p_k = 1\) y \(p_{k} \geq 0\) para todo \(k\).
Lo que interesa en este estudio es \emph{inferir} quiénes son las
\(p_k\) para determinar si es más probable que caiga en un lado que en
otro. Las \(p_k\) se conocen como parámetros.

\emph{Mundo real}

Ya en la realidad en esos \(10\) tiros no observamos cualquier cosa,
observamos valores específicos que hacen que \textbf{la muestra
aleatoria observada} sea: \[
s_n = \{x_1, x_2, \dots, x_{10} \} = \{2,6,1,3,3,3,5,1,3,2\}.
\] Por supuesto que repitiendo el experimento (volviendo a tirar el dado
10 veces) lo más probable es que la \textbf{muestra aleatoria observada}
cambie (y veamos otros números) pero el modelo, reflejado en la
\textbf{muestra aleatoria} (teórica), permanezca inmutable. Una forma de
estimar las probabilidades podría ser mediante proporciones y calcular,
por ejemplo, la probabilidad de que aparezca \(1\) como: \[
\hat{p}_1 = \frac{\text{Veces que aparece 1}}{n} = \frac{2}{10}
\] En este caso, \(\hat{p}_1\) dado por \(\frac{2}{10}\) es un
\textbf{estimador observado} de la verdadera probabilidad \(p_1\) que
vive en el mundo de los modelos (y jamás podremos conocer)
\end{Ejemplo}

Armados con el ejemplo anterior realicemos la definición de las muestras observadas:

\begin{Definicion}
\hypertarget{muestra-observada}{%
\subsubsection{Muestra observada}\label{muestra-observada}}

Una muestra observada es una colección no vacía de valores codificados
como números reales los cuales corresponden a realizaciones de una
muestra \(\mathcal{X}\). Usualmente la denotamos: \[
s = \{ x_1, x_2, \dots\}
\] donde las \(x_i\) \textbf{NO SON VARIABLES ALEATORIAS} sino que son
datos \textbf{fijos} ya observados.
\end{Definicion}

\begin{Definicion}
\hypertarget{muestra-aleatoria-observada}{%
\subsubsection{Muestra aleatoria
observada}\label{muestra-aleatoria-observada}}

Una muestra aleatoria observada es una colección no vacía de tamaño
\(n\) de valores codificados como números reales los cuales corresponden
a realizaciones de una muestra aleatoria \(\mathcal{X}_{(n)}\). En
particular suponemos que \(x_1\) es el valor observado de la variable
aleatoria \(X_1\), \(x_2\) es el valor observado de la variable
aleatoria \(X_2\) y así sucesivamente. Generalmente la denotamos por: \[
s_{(n)} = \{ x_1, x_2, \dots, x_n\}
\] donde las \(x_i\) \textbf{NO SON VARIABLES ALEATORIAS} sino que son
datos \textbf{fijos} ya observados.
\end{Definicion}

Veamos un segundo ejemplo:

\begin{Ejemplo}
\hypertarget{cantidad-de-personas-que-llegan-a-una-tienda}{%
\subsubsection{Cantidad de personas que llegan a una
tienda}\label{cantidad-de-personas-que-llegan-a-una-tienda}}

En muchos casos la llegada de personas se supone que sigue una
distribución Poisson. En este caso nos interesa estimar el número
promedio de personas por día que hay en una tienda de la cual se han
medido las siguientes cantidades (por día). Suponemos que las llegadas
son independientes entre sí (la cantidad de gente que llegó un día no
influye en la cantidad que llegó el otro).

\begin{longtable}[]{@{}ll@{}}
\toprule
\textbf{Día} & \textbf{Número de personas}\tabularnewline
\midrule
\endhead
1 & 50\tabularnewline
2 & 45\tabularnewline
3 & 60\tabularnewline
4 & 65\tabularnewline
5 & 55\tabularnewline
6 & 40\tabularnewline
\bottomrule
\end{longtable}

\emph{Mundo del modelo}

La población en este caso es el conjunto infinito de todas las posibles
formas en que en un día pueden llegar personas. De ese conjunto
obtenemos una muestra aleatoria de tamaño \(n = 6\) (suponemos que las
observaciones son independientes entre sí) dada por: \[
X_{(n)} = \{ X_1, X_2, X_3, X_4, X_5, X_6\}
\] donde las \(X_i \sim \text{Poisson}(\lambda)\) (todas con el mismo
\(\lambda\)). Recordamos que la media de una Poisson es \(\lambda\) por
lo que el \textbf{parámetro} que nos interesa estimar es \(\lambda\).

\emph{Mundo real}

A partir de las \(6\) llegadas observadas construimos \textbf{la muestra
aleatoria observada}: \[
s_n = \{x_1, x_2, x_3, x_4, x_5, x_6 \} = \{50, 45, 60, 65, 55, 40\}.
\] Una forma de estimar la media \(\lambda\) es mediante el siguiente
\textbf{estimador observado}: \[
\hat{\lambda} = \frac{1}{6} \sum_{i = 1}^6 x_i = 52.5
\] Ojo, esto no significa que \(\lambda\) \emph{sea} \(52.5\). Significa
que nuestra hipótesis de quién es \(\lambda\) es \(52.5\) y que
esperaríamos la próxima vez en la tienda \(52\) ó \(53\) personas. En el
mundo real \emph{quién sabe cuánto vale \(\lambda\)} , nuestra hipótesis
es que vale \(52.5\) pero eso no necesarimente es la realidad.
\end{Ejemplo}

Como ya establecimos, muchas veces el modelo utiliza un \textbf{parámetro} el cual es desconocido. A partir de los datos construimos un \textbf{estimador observado} el cual es nuestra hipótesis del verdadero valor del parámetro. En general va a ser imposible que le atinemos al \emph{verdadero} valor del parámetro pero la idea es que el \textbf{estimador observado} esté lo suficientemente cerca. En el ejemplo anterior nos gustaría, por ejemplo, que el verdadero parámetro quizá fuera \(\lambda = 52\) ó \(\lambda = 54\) pero nos sacaría mucho de onda que el parámetro real fuera \(\lambda = 1000000\).

\begin{Definicion}
\hypertarget{distirbuciuxf3n-paramuxe9trica}{%
\subsubsection{Distirbución
paramétrica}\label{distirbuciuxf3n-paramuxe9trica}}

Una función de distirbución acumulada es una \textbf{distribución
paramétrica} con parámetro \(\vec{\theta}\) si dada una colección de
distribuciones \[
\{ F_{\vec{\theta}} | \theta \in \Theta \}
\] determinar \(\vec{\theta}\) determina la distribución. Es decir, la
familia de distribuciones está indizada por \(\vec{\theta}\). A
\(\vec{\theta}\) se le conoce como el \textbf{parámetro} o
\textbf{vector de parámetros}.
\end{Definicion}

La definición anterior suena muy compleja sin embargo los ejemplos ya los conocemos.

\begin{Ejemplo}
\hypertarget{la-normal}{%
\subsubsection{La normal}\label{la-normal}}

La distribución normal es una distribución paramétrica con \[
\vec{\theta} = (\mu, \sigma^2)^T
\] el vector de parámetros dado por la media y la varianza.
\end{Ejemplo}

\begin{Ejemplo}
\hypertarget{la-exponencial}{%
\subsubsection{La exponencial}\label{la-exponencial}}

La distribución exponencial es una distribución paramétrica con \[
\theta = \lambda
\] el parámetro que establece la tasa de la exponencial.
\end{Ejemplo}

\begin{Ejemplo}
\hypertarget{la-normal-con-varianza-1}{%
\subsubsection{La normal con varianza
1}\label{la-normal-con-varianza-1}}

La distribución normal con varianza 1 es una distribución paramétrica
con \[
\theta = \mu
\] En este caso la varianza es conocida (\(\sigma^2 = 1\)) pero la media
no por eso sólo la media es el parámetro.
\end{Ejemplo}

Podemos entonces definir un \textbf{estimador}:

\begin{Definicion}
\hypertarget{estimador}{%
\subsubsection{Estimador}\label{estimador}}

Dada una distribución paramétrica \(F_{\theta}\) con parámetro
\(\theta\) un estimador \(\hat{\theta}\) de \(\theta\) es una variable
aleatoria que se construye como función de la muestra aleatoria: \[
\hat{\theta}: \mathcal{X}_{(n)} \to \Theta
\] Como \(\hat{\theta}\) es una función de la muestra aleatoria entonces
puede representarse como: \[
\hat{\theta} = \hat{\theta}(X_1, X_2, \dots, X_n)
\]
\end{Definicion}

Dado un conjunto de datos, el \textbf{estimador observado de \(\theta\)} es el estimador \(\hat{\theta}\) de \(\theta\) evaluado en los datos.

\begin{Definicion}
\hypertarget{estimador-observado}{%
\subsubsection{Estimador observado}\label{estimador-observado}}

Dada una distribución paramétrica \(F_{\theta}\) con parámetro
\(\theta\) con estimador \(\hat{\theta}\) y datos observados
\(s_{(n)} = \{x_1, x_2, \dots, x_n\}\) el \textbf{estimador observado}
corresponde a la evaluación de \(\hat{\theta}\) en \(s_{(n)}\); es
decir: \[
\hat{\theta}(x_1, x_2, \dots, x_n)
\]
\end{Definicion}

Veamos ejemplos para entender mejor cómo funciona esto.

\begin{Ejemplo}
\hypertarget{tiros-de-una-moneda}{%
\subsubsection{Tiros de una moneda}\label{tiros-de-una-moneda}}

Se tiene una moneda que cae más de un lado que del otro. Interesa
estimar \(p\) la probabilidad de que caiga cruz. Para ello se toma una
\textbf{muestra aleatoria} de \(5\) tiros de la moneda: \[
X_{(n)} = \{X_1, X_2, \dots, X_{5} \}
\] Suponemos que los tiros son independientes. El modelo entonces
implicaría que \[
X_i \sim \text{Bernoulli}(p)
\] para cada \(i = 1, 2, \dots, 5\). Si codificamos cruz como \(1\) y
cara como \(0\), la \textbf{muestra aleatoria observada} es: \[
s_{(n)} = \{1,1,1,0,1\} = \{x_1, x_2, \dots, x_5\}
\] donde tuvimos tres cruces continuas, luego una cara y finalmente una
cruz. Una opción de estimador observado sería contar la proporción de
cruces haciendo: \[
\hat{\theta}(x_1, \dots, x_5) = \frac{1}{n} \sum_{k = 1}^n x_i = \frac{4}{5}
\] de donde diríamos que nuestra hipótesis de cuánto vale el parámetro
\(p\) es \(4/5\). Por otro lado, el \textbf{estimador} teórico es: \[
\hat{\theta}(X_1, \dots, X_5) = \frac{1}{n} \sum_{k = 1}^n X_i 
\] el cual tiene una distribución de probabilidad sencilla pues
\(\sum_{k = 1}^n X_i \sim \textrm{Binomial}(n,p)\). Particularmente
podemos calcular su valor esperado, por ejemplo, \[
\mathbb{E}\Big[  \hat{\theta}(X_1, \dots, X_5) \Big]  =  \mathbb{E}\Big[  \frac{1}{n} \sum_{k = 1}^n X_i  \Big] = \frac{1}{n}\sum_{k = 1}^n \mathbb{E}\Big[X_i \Big] = \frac{1}{n}\sum_{k = 1}^n  p = \frac{1}{n} np = p
\] lo cual implica que el estimador, en promedio, devolvería el
parámetro que nos interesa (esta propiedad se conoce como \emph{ser
insesgado} y lo veremos más adelante).
\end{Ejemplo}

\begin{Ejemplo}
\hypertarget{error-de-mediciuxf3n-de-una-app}{%
\subsubsection{Error de medición de una
app}\label{error-de-mediciuxf3n-de-una-app}}

Una app que se dedica a medir la altura de edificios mediante la toma de
videos tiene un error de medición con distribución normal y cuya
varianza es \(1\). Interesa determinar el error de medición promedio, el
parámetro \(\mu\). Para ello se toman videos y se miden edificios para
obtener una colección de 7 errores de medición independientes en la
siguiente \textbf{muestra aleatoria}: \[
X_{(n)} = \{X_1, X_2, \dots, X_{5} \}
\] El modelo es \[
X_i \sim \text{Normal}(\mu, 1)
\] para cada \(i = 1, 2, \dots, 7\). Si los datos fueron:

\begin{longtable}[]{@{}ll@{}}
\toprule
\textbf{Edificio} & \textbf{Error de medición}\tabularnewline
\midrule
\endhead
Bellas Artes & 12.11\tabularnewline
Torre Latinoamericana & 40.54\tabularnewline
Catedral Metropolitana & 22.07\tabularnewline
Palacio Nacional & 15.22\tabularnewline
Rectoría de la UNAM & 45.18\tabularnewline
Guerrero Chimalli & 33.39\tabularnewline
Estadio Azteca & 41.76\tabularnewline
\bottomrule
\end{longtable}

la \textbf{muestra aleatoria observada} en este caso correspondió : \[
s_{(n)} = \{12.11,40.54,22.07,15.22,45.18, 33.39, 41.76\} = \{x_1, x_2, \dots, x_7\}
\] Una opción de estimador observado sería calcular la media muestral
haciendo: \[
\hat{\theta}(x_1, \dots, x_7) = \frac{1}{n} \sum_{k = 1}^n x_i = 30.03857
\] de donde diríamos que nuestra hipótesis de cuánto vale el parámetro
\(\mu\) es \(30.03857\). Por otro lado, el \textbf{estimador} teórico
es: \[
\hat{\theta}(X_1, \dots, X_7) = \frac{1}{n} \sum_{k = 1}^n X_i 
\] tiene una distribución de probabilidad sencilla pues sabemos que
\(\sum_{k = 1}^n X_i \sim \textrm{Normal}(\mu,\sigma^2)\).
Particularmente podemos calcular su valor esperado, por ejemplo, \[
\mathbb{E}\Big[  \hat{\theta}(X_1, \dots, X_7) \Big]  =  \mathbb{E}\Big[  \frac{1}{n} \sum_{k = 1}^n X_i  \Big] = \frac{1}{n}\sum_{k = 1}^n \mathbb{E}\Big[X_i \Big] = \frac{1}{n}\sum_{k = 1}^n  \mu = \frac{1}{n} n\mu = \mu
\] lo cual implica que el estimador, en promedio, devolvería el
parámetro que nos interesa (este también es \emph{insesgado}).
\end{Ejemplo}

A modo de resumen y para concluir este capítulo introductorio, veamos un ejemplo más desarrollado de inferencia estadística.

\hypertarget{inferencia-estaduxedstica-ejemplo.}{%
\section{Inferencia estadística: ejemplo.}\label{inferencia-estaduxedstica-ejemplo.}}

Se tiene una caja con cinco pelotas de colores rojo \(R\) y azul \(A\). Las pelotas son indistinguibles\footnote{Pelotas distinguibles, por ejemplo, tendrían números distintos o serían de materiales diferentes o con marcas específicas para saber que una azul es distinta de la otra.} entre sí salvo por el color. Se desconoce exactamente la proporción de colores de la caja (es decir no se sabe cuál de las siguientes opciones es: \(\{ R, R, R, R, R\}\), \(\{ R, R, R, R, A\}\), \(\{ R, R, R, A, A\}\), \(\{ R, R, A, A, A\}\), \(\{ R, A, A, A, A\}\), \(\{ A, A, A, A, A\}\)) y eso es lo que se desea determinar. Para ello se extrae una bola, se anota que su color fue rojo, \(R\), y se devuelve a la caja. Se extrae otra bola (que, pudo haber sido la misma que la inicial, recuerda que las bolas son indistinguibles y que la anterior se devolvió a la caja), se anota que su color fue rojo \(R\) y se devuelve a la caja. Finalmente en la tercera extracción sale una pelota azul \(A\). Los datos observados (y ordenados) son los siguientes \(( R, R, A)\). Hay dos estimadores posibles de la probabilidad de que salga rojo \(p\) que podemos calcular a partir de la \textbf{muestra aleatoria} ordenada \(( R, R, A)\)

\hypertarget{estimador-de-momentos}{%
\subsection{Estimador de momentos}\label{estimador-de-momentos}}

Una opción es estimar la probabilidad de que salga rojo, \(p\), mediante el conteo de cuántos rojos salieron divididos entre el total de extracciones. En este caso tendríamos el estimador evaluado en la muestra:
\[
\hat{p}_M = \frac{2}{3}
\]
Aquí una nota bien importante: es imposible \emph{(¿por qué?)} que en la vida real la probabilidad \(p\) de que salga rojo sea \(2/3\). El \(\hat{p}\) es un estimador pero que jamás va a coincidir con el valor de verdad.\footnote{Esto porque en la caja hay cinco pelotas y el denominador de la probabilidad \(p\) va a ser \(5\) por construcción del modelo. No hay forma de que el \(5\) se pueda simplificar en \(3\) o viceversa.}. Sin embargo este estimador \(\hat{p}\) tiene características interesantes. Para verlas, definamos primero una \textbf{muestra aleatoria} de tamaño \(3\) de las pelotas en la urna:
\[
X_{(n)} = \{ X_1, X_2, X_3\}
\]
donde marcaremos \(X_i = 1\) si salió rojo y \(X_i = 0\) si salió azul. Preguntarnos por la probabilidad de rojo es lo mismo que preguntarnos por la probabilidad de que \(X_i = 1\). El estimador \(\hat{p}\) evaluado en la muestra, la suma ponderada de todos, (los rojos aportan \(1\) y los azules nada) está dado por:

\[
\hat{p}(X_1, X_2, X_3) = \frac{1}{3}(X_1 + X_2 + X_3)
\]

Notamos que para este caso los datos (muestra aleatoria observada) son \(x_1 = 1\), \(x_2 = 1\) y \(x_3 = 0\). Por lo que el estimador observado es:

\[
\hat{p}(x_1, x_2, x_3) = \frac{1}{3}(x_1 + x_2 + x_3) = \frac{2}{3}
\]

Notamos que el estimador \(\hat{p}\) es una variable aleatoria que depende de la muestra (aleatoria). Una vez que se tiene la muestra el estimador \(\hat{p}\) colapsa en un único número real definido por la tabla. Pero antes de hacer el experimento (o bien si repetimos el experimento) el \(\hat{p}\) es una variable aleatoria que puede obtener múltiples valores distintos. Como es una variable aleatoria podemos entonces calcular su varianza, por ejemplo, así como su media:

\[
\begin{aligned}
\mathbb{E}\Big[ \hat{p} \Big] & =  \frac{1}{3}\mathbb{E}\big[ X_1 + X_2 + X_3\big]
\\ & = \frac{1}{3}\big( \mathbb{E}[ X_1] + \mathbb{E}[ X_2] + \mathbb{E}[ X_3]\big)
\\ & = \frac{1}{3} 3p 
\\ & = p
\end{aligned}
\]

por lo que si hiciéramos el ejercicio de muestreo múltiples veces los estimadores \(\hat{p}\) que obtuviéramos le atinarían en promedio a \(p\). Por otro lado la varianza está dada por:

\[
\begin{aligned}
\textrm{Var}Big[ \hat{p} \Big] & =  \frac{1}{9}\textrm{Var}\big[ X_1 + X_2 + X_3\big]
\\ & = \frac{1}{9}\big( \textrm{Var}[ X_1] + \textrm{Var}[ X_2] + \textrm{Var}[ X_3]\big)
\\ & = \frac{1}{9} 3p (1 - p)
\\ & = \frac{1}{3} p (1 - p)
\end{aligned}
\]

Podemos calcular más propiedades probabilísticas de \(\hat{p}\) pero el punto importante es que el \(\hat{p}\) tiene su propia distribución.

En \texttt{R} podemos simular este proceso de extracción de los \(\hat{p}\):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\CommentTok{# Número de veces que haremos el experimento de extraer 3 pelotas}
\NormalTok{nsim           <-}\StringTok{ }\DecValTok{100}
\NormalTok{tamaño.muestra <-}\StringTok{ }\DecValTok{3}

\CommentTok{#La verdadera población}
\NormalTok{poblacion <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"R"}\NormalTok{,}\StringTok{"R"}\NormalTok{,}\StringTok{"R"}\NormalTok{,}\StringTok{"A"}\NormalTok{,}\StringTok{"A"}\NormalTok{)}

\CommentTok{#Aquí guardaremos los valores de pgorro}
\NormalTok{pgorro    <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{, nsim)}

\CommentTok{#Repetimos el proceso de muestreo n veces}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nsim)\{}
\NormalTok{  muestra      <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(poblacion, tamaño.muestra, }\DataTypeTok{replace =}\NormalTok{ T)}
\NormalTok{  conteo_rojos <-}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{which}\NormalTok{(muestra }\OperatorTok{==}\StringTok{ "R"}\NormalTok{))}
\NormalTok{  pgorro[i]    <-}\StringTok{ }\NormalTok{conteo_rojos}\OperatorTok{/}\NormalTok{tamaño.muestra}
\NormalTok{\}}

\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ pgorro, }\DataTypeTok{y =}\NormalTok{ ..count..}\OperatorTok{/}\DecValTok{100}\NormalTok{), }
                 \DataTypeTok{bins =} \DecValTok{10}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"purple"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"white"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}
    \DataTypeTok{x =} \StringTok{"Valores de pgorro"}\NormalTok{,}
    \DataTypeTok{y =} \StringTok{"Masa de probabilidad de pgorro"}\NormalTok{,}
    \DataTypeTok{title =} \StringTok{"Función de masa de probabilidad de pgorro"}\NormalTok{,}
    \DataTypeTok{subtitle =} \StringTok{"Aproximación por simulaciones"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics{InferenciaEstadistica_files/figure-latex/unnamed-chunk-18-1.pdf}

Esto implica que aunque tengamos datos fijos \(\{ R,R,R A, A\}\) como la extracción de la muestra es aleatoria el valor de \(\hat{p}\) va a variar por el simple proceso de selección aleatoria de la muestra. Darnos cuenta de qué tanto varía nuestro valor a estimar y cómo se aleja (o no) de la verdad va a ser un punto muy importante (en general queremos estimadores \(\hat{p}\) que no se alejen de los valores verdaderos).

Ahora, los estimadores \(\hat{p}\) no son únicos y se nos puede ocurrir otro estimador como ejemplo:

\hypertarget{estimador-de-muxe1xima-verosimilitud-maximizaciuxf3n-discreta}{%
\subsection{Estimador de máxima verosimilitud (maximización discreta)}\label{estimador-de-muxe1xima-verosimilitud-maximizaciuxf3n-discreta}}

Una segunda opción es buscar bajo qué valor de \(p\) (de muchos posibles) son más probables los datos observados. Este criterio se conoce como el criterio de \textbf{máxima verosimilitud}. La idea es ver, bajo cada una de las construcciones posibles de la caja (\emph{i.e.} \(\{ R, R, R, R, R\}\), \(\{ R, R, R, R, A\}\), \(\{ R, R, R, A, A\}\), \(\{ R, R, A, A, A\}\), \(\{ R, A, A, A, A\}\), \(\{ A, A, A, A, A\}\)) son más probables los datos observados \(( R, R, A)\) y elegir esa caja.
Vamos a resolver este problema calculando bajo cada escenario de caja las probabilidades de obtener la combinación observada \(( R, R, A)\).

La pregunta, antes de resolver el problema, es \emph{¿y esto para qué sirve?} . Si bien los ejercicios de pelotas de colores y cajas son divertidos, estos por sí mismos no llegan muy lejos. Lo importante es que los ejercicios de urnas \emph{son abstracciones} de problemas reales. Por ejemplo, el problema de urnas ocurre de manera poblacional cuando nos interesa estimar una proporción. En un país hay personas que padecen diabetes R y sin diabetes A. Se sabe que en el país hay 100 millones de personas. La proporción exacta (dentro del país) es desconocida. Sin embargo podemos hacer una encuesta y obtener una muestra de 100 personas dentro de las cuáles 20 padecieron diabetes y 80 no (\(\{20 R, 80 A\}\)). De aquí, usando el mismo razonamiento que usaremos con la caja de pelotas podemos buscar la combinación de personas con diabetes y sin diabetes en el país donde la combinación de \(\{20 R, 80 A\}\) es la más probable.

Este mismo razonamiento puede cambiarse de múltiples formas. En una encuesta podemos tener más de dos opciones. Por ejemplo, si interesa determinar la cantidad de personas que votarían por el partido rojo \(R\), por el azul \(A\) o por el negro \(B\) el modelo de pelotas en una caja ahora tiene tres tipos de pelota (y si hay \(n\) partidos habría \(n\) colores). Puede que los colores estén relacionados entre sí y extraer uno garantice la extracción de otro (por ejemplo si se entrevista gente en casas es muy probable que si se vive un niño en una casa \emph{a fuerza} viva un adulto en ella mientras que la relación inversa no funciona: que un adulto habite una casa no determina que viva un niño en la misma). Otros cambios posibles son en el mecanismo de selección. Pudiera ser que las pelotas rojas \(R\) fueran más grandes que las azules \(A\) de tal forma que cuando se extrajeran hubiera mayor probabilidad de tener rojas en la muestra. Esto pasa, por ejemplo, cuando se hacen encuestas de productos. Generalmente sólo aquellas personas que tienen un sentimiento muy fuerte hacia un producto contestan la encuesta. De ahí que haya muchísimas reseñas diciendo que los productos son malísimos o buenísimos y nada intermedio: la gente que reseña algo con 3 estrellas son las pelotas azules que son más difíciles de extraer. Poco a poco veremos otros problemas con pelotas y urnas con sus análogos al mundo real. Por ahora resolvamos el que se especifica más arriba.

\hypertarget{ejemplo-5-muestreo-de-urna-con-dos-clases-con-orden-con-reemplazo}{%
\subsection{Ejemplo 5: Muestreo de urna con dos clases, con orden, con reemplazo}\label{ejemplo-5-muestreo-de-urna-con-dos-clases-con-orden-con-reemplazo}}

Considera una urna con cinco pelotas de colores rojo \(R\) y azul \(A\). Se desconoce la proporción de pelotas en la urna. Las pelotas son indistinguibles entre sí salvo por el color. Se extrae de manera ordenada primero una bola roja, \(R\), y se devuelve a la urna. Luego se extrae una segunda bola roja, \(R\), y se devuelve a la urna. Finalmente se extrae una tercera bola y resulta azul: \(A\). La combinación ordenada de pelotas extraídas es: \(( R, R, A)\). Suponiendo todas las pelotas tienen la misma probabilidad de salir, cuál urna genera con mayor probabilidad los datos observados (y por tanto sería nuestra opción para decidir qué urna es la que tenemos): \(\{ R, R, R, R, R\}\), \(\{ R, R, R, R, A\}\), \(\{ R, R, R, A, A\}\), \(\{ R, R, A, A, A\}\), \(\{ R, A, A, A, A\}\) ó \(\{ A, A, A, A, A\}\).

\begin{quote}
\hypertarget{soluciuxf3n-5-muestreo-de-urna-con-dos-clases-con-orden-con-reemplazo}{%
\subsection{Solución 5: Muestreo de urna con dos clases, con orden, con reemplazo}\label{soluciuxf3n-5-muestreo-de-urna-con-dos-clases-con-orden-con-reemplazo}}

Hay dos combinaciones de posible urna que podemos descartar desde un inicio: la que sólo tiene rojos \(\{ R, R, R, R, R\}\) y la que sólo tiene azules \(\{ A, A, A, A, A\}\). Esto porque los datos observados nos muestran que obtuvimos tantos rojos como azules. En estas dos descartadas la probabilidad de obtener \(( R, R, A)\) es cero. Quedan como cajas posibles: la de cuatro rojas \(\{ R, R, R, R, A\}\), la de tres rojas \(\{ R, R, R, A, A\}\), la de tres azules \(\{ R, R, A, A, A\}\), la de una roja \(\{ R, A, A, A, A\}\). Comenzaré mi análisis con la primera que puse: los otros análisis son similares.

\textbf{Análisis de \(\{ R, R, R, R, A\}\)}

Una de las formas más posibles de enlistar todos los escenarios es con un árbol. La forma larga (e impráctica) consiste en enlistar cada una de las formas de extraer las pelotas de la urna como muestra la siguiente imagen:

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_1.jpeg}
\caption{Árbol de decisión para el análisis de \(\{ R, R, R, R, A\}\) con reemplazo}
\end{figure}

Esta es una forma ``segura'' de resolver un problema: puede ser largo pero si no se te olvida nada ¡siempre es una posibilidad! Observa que de todas las opciones (combinadas del primer nodo,el segundo y el tercero) se tienen 16 extracciones de la forma \(( R, R, A)\) de un total de 125 extracciones (\(5\) opciones en el último nodo por \(5\) formas de extraer el segundo por \(5\) opciones primeras dan 125). La probabilidad entonces de extraer \(( R, R, A)\) bajo este esquema es:
\[
\textrm{Probabilidad de ( R, R, A) dada la urna \{ R, R, R, R, A\} con reemplazo} =  \dfrac{16}{125} 
\]

\textbf{Análisis de \(\{ R, R, R, A, A\}\)}

Vale la pena para este segundo análisis podar un poco el árbol. Podemos darnos cuenta que en el caso anterior todas las ramas rojas son iguales por lo que quizá no vale la pena ponerlas todas. Al calcular la probabilidad de la extracción \(( R, R, A)\) dado que la urna es de la forma \(\{ R, R, R, A, A\}\) trabajaremos más a fondo el árbol. El árbol inicial es como sigue:

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_2.jpeg}
\caption{Árbol de decisión en el caso \(\{ R, R, R, A, A\}\) con reemplazo}
\end{figure}

En este caso notamos que todos los caminos iniciados por rojo, R, son idénticos lo mismo que los caminos iniciados por azul A por lo que podemos simplificar el árbol copiando sólo las ramas distintas y anotando cada rama a cuántas representa (las azules son \(2\) de \(5\) mientras que las rojas \(3\) de \(5\) de ahí los números \(2/5\) y \(3/5\)).

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_2_1.jpeg}
\caption{Árbol de decisión simplificado para el análisis de \(\{ R, R, R, A, A\}\) con reemplazo}
\end{figure}

Para el caso que nos atañe en esta ocasión: obtener primero roja, luego otra roja y finalmente azul, \(( R, R, A)\), la única opción es la rama de abajo con probabilidades dadas por:
\[
\textrm{Probabilidad de ( R, R, A) dada la urna \{R, R, R, A, A\} con reemplazo}  = \dfrac{3 \times 3 \times 2}{5 \times 5 \times 5} = \dfrac{18}{125}
\]
Esta forma reducida es equivalente a la que hubiéramos obtenido haciendo el análisis completo del árbol (por la primera imagen donde hay \(18\) opciones de \(125\) resultados). El producto de arriba refiere a el número de opciones para primera roja, por el número de opciones para segunda roja \emph{dado} que la primera fue roja y la última son las opciones para una tercera azul \emph{condicional} en que las dos primeras fueron rojas. En el denominador sólo multiplicamos los casos totales que son \(5\) ramas iniciales que ramifican en \(5\) nodos secundarios y \(5\) hojas finales.

Tómate unos minutos para intentar justificar por qué este conteo de multiplicaciones es equivalente a haber contado todas. Asegúrate de entenderlo bien antes de continuar ¡volveremos a ello más adelante!

\textbf{Análisis de \(\{ R, R, A, A, A\}\)}

En este análisis usaremos el mismo truco de un árbol de decisiones reducido que usamos la vez pasada. Lo construiremos paso a paso para mostrar el proceso. De manera inicial tenemos dos opciones: roja (\(2\) bolas de \(5\)) ó azul (\(3\) bolas de \(5\)) por lo que a partir de la raíz construimos el árbol con las dos opciones y sus probabilidades

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_3_1.jpeg}
\caption{Versión 1 del árbol de decisión simplificado para \(\{ R, R, A, A, A\}\) con reemplazo}
\end{figure}

Dentro de la rama azul de nuevo tenemos la posibilidad de extraer rojas (\(2\) de \(5\)) o azules (\(3\) de \(5\)) por lo que se acoplan a la rama:

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_3_2.jpeg}
\caption{Versión 2 del árbol de decisión simplificado para \(\{ R, R, A, A, A\}\) con reemplazo}
\end{figure}

La lógica es idéntica si salió roja: hay \(2/5\) de probabilidad de extraer una roja o \(3/5\) de extraer una azul

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_3_3.jpeg}
\caption{Versión 3 del árbol de decisión simplificado para \(\{ R, R, A, A, A\}\) con reemplazo}
\end{figure}

Finalmente las últimas ramas del árbol se agregan de manera idéntica: \(2/5\) de rojas y \(3/5\) de azul en cada una de las posibles extracciones.

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_3_4.jpeg}
\caption{Versión final del árbol de decisión simplificado para \(\{ R, R, A, A, A\}\) con reemplazo}
\end{figure}

Notamos entonces que podemos hacer el cálculo multiplicando (como hicimos la vez pasada) para obtener:
\[
\textrm{Probabilidad de ( R, R, A) dada la urna \{R, R, A, A, A\} con reemplazo}  = \dfrac{2}{5} \cdot \dfrac{2}{5} \cdot \dfrac{3}{5} = \dfrac{12}{125}
\]

\textbf{Análisis de \(\{ R, A, A, A, A\}\)}

Ya para este último caso los árboles de decisiones te son familiares por lo que puedes verificar que en este caso el árbol es el siguiente:

\begin{figure}
\centering
\includegraphics{./images/arbol_decision_4.jpeg}
\caption{Árbol de decisión simplificado para el análisis de \(\{ R, A, A, A, A\}\) con reemplazo}
\end{figure}

donde la probabilidad de \$( R, R, A) \$ dado que la urna es \(\{ R, A, A, A, A\}\) está dada por:
\[
\textrm{Probabilidad de ( R, R, A) dada la urna \{ R, A, A, A, A\} con reemplazo} = \dfrac{1}{5} \cdot \dfrac{1}{5} \cdot \dfrac{4}{5} = \dfrac{4}{125}.
\]

\textbf{Conclusión}

Después de que analizamos las probabilidades bajo todas las combinaciones posibles de urna concluimos que la que tiene probabilidad más alta de generar en ese orden rojo, luego rojo y finalmente azul, \(( R, R, A)\), es la urna \(\{R, R, R, A, A\}\) pues si la urna tiene esa combinación de pelotas la probabilidad de extraer \(( R, R, A)\) es:
\[
\textrm{Probabilidad de ( R, R, A) dada la urna \{R, R, R, A, A\} con reemplazo} = \dfrac{18}{125} = 0.144.
\]
Siguiendo la idea de que la urna que tenemos es la que tiene mayor probabilidad de generar los datos observados (esto se conoce como \emph{criterio de máxima verosimilitud} en estadística) entonces estimaríamos que la urna que tenemos es \(\{R, R, R, A, A\}\) por lo que \(\hat{p} = \frac{3}{5}\) es el estimador de máxima verosimilitud de \(p\).

\textbf{OJO} Dadas las observaciones \(( R, R, A)\) no podemos determinar a ciencia cierta cuál es la combinación de pelotas en la urna que tenemos. Por lo que siempre puede pasar que la combinación \emph{real} sea distinta. Aquí el modelo nos dice por cuál optar (de manera lógica, aquella que genera con mayor probabilidad lo que observamos) pero la realidad ¡puede estar por otro lado!
\end{quote}

Una vez que obtuvimos el estimador, \(\hat{p}\), la segunda pregunta que nos interesará resolver es \emph{qué tan buen estimador es \(\hat{p}\)}. Para ello también buscaríamos describir su distribución probabilística (su masa, su varianza, su valor esperado). Esto lo dejaremos para más adelante.

\hypertarget{resumen-de-la-secciuxf3n}{%
\section{Resumen de la sección}\label{resumen-de-la-secciuxf3n}}

En esta sección aprendimos que, en el mundo de las ideas, tenemos poblaciones de las cuales obtenemos subconjuntos (muestras). Las muestras observadas corresponden a los datos mientras que las muestras (sin el ``observadas'') corresponden al modelo en el mundo de las ideas. Lo que buscamos es estimar los valores que necesitamos para determinar el modelo (parámetros) y esos valores se obtienen a través de estimadores (puede haber varios para el mismo parámetro). Los estimadores viven también en el mundo de los modelos y ahí tienen su distribución de probabilidad, sus masas y densidades, sus valores esperados y sus varianzas. Describir esto nos ayuda a saber cómo se comportan los estimadores y decidir cuáles son los buenos. Profundizaremos más en la siguiente sección donde haremos un ejemplo muy específico: ¿qué pasa si mi población está compuesta de variables aleatorias normales? Jugaremos con ello y veremos por qué es normal usar la normal.

  \bibliography{book.bib,packages.bib}

\end{document}
